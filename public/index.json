[{"authors":["admin"],"categories":null,"content":"I am an analyst at Wayfair, Inc., working within the Forecasting Analytics team within the larger Workforce Management group. In the past I\u0026rsquo;ve worked as an independent researcher with both the Stella Riparian and Stream Ecology and Yanai Forest Ecosystem Science laboratories, as well as the Beaver Impact Assessment intern for the New York State Department of Environmental Conservation. In all of these roles I\u0026rsquo;ve worked to apply data science techniques to large-scale challenges, frequently serving as the statistical and technical expert within my team.\nMy past projects have included assessing the landscape-level impacts of ecosystem engineers within New York\u0026rsquo;s Adirondack State Park, as well as investigating the impact of fertilization on beech bark disease within the White Mountains of New Hampshire. I\u0026rsquo;ve also written a primer on how to use R for data exploration and analysis in both scientific and business contexts.\n","date":1573862400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1573923772,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.mikemahoney218.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an analyst at Wayfair, Inc., working within the Forecasting Analytics team within the larger Workforce Management group. In the past I\u0026rsquo;ve worked as an independent researcher with both the Stella Riparian and Stream Ecology and Yanai Forest Ecosystem Science laboratories, as well as the Beaver Impact Assessment intern for the New York State Department of Environmental Conservation. In all of these roles I\u0026rsquo;ve worked to apply data science techniques to large-scale challenges, frequently serving as the statistical and technical expert within my team.","tags":null,"title":"Mike Mahoney","type":"authors"},{"authors":null,"categories":null,"content":" Introduction to Data Visualization Data visualization \u0026ndash; our working definition will be \u0026ldquo;the graphical display of data\u0026rdquo; \u0026ndash; is one of those things like driving, cooking, or standup: everyone thinks they\u0026rsquo;re really great at it, because they\u0026rsquo;ve been doing it for a while, and yet many \u0026ndash; if not most \u0026ndash; people don\u0026rsquo;t even know where they could start learning how much better they could be doing things. For something so essential to so many people\u0026rsquo;s daily work, data visualization is so rarely directly taught, and is usually assumed to be something people will pick up with time.\nHowever, that isn\u0026rsquo;t the best approach. Data visualization is a skill like any other, and even experienced practicioners could benefit from honing their skills in the subject. Hence, this short lesson on the topic. This set of three documents contain about the same amount of information as could be covered in a 60-90 minute lecture on the subject.\nThis page serves as a landing page for the course as a whole \u0026ndash; use the menu above to navigate between courses on the site. You can find the full code used to make these graphs \u0026ndash; and to generate this tutorial itself \u0026ndash; on GitHub.\n","date":1570579200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1570680788,"objectID":"7a3bb1642cd1eeeceef582c7d2887c5a","permalink":"https://www.mikemahoney218.com/tutorials/dataviz/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/tutorials/dataviz/","section":"tutorials","summary":"An introduction to the introduction to data visualization course.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":["Tutorials","DataViz"],"content":" \nData visualization – our working definition will be “the graphical display of data” – is one of those things like driving, cooking, or being funny: everyone thinks they’re really great at it, because they’ve been doing it for a while, and yet many – if not most – people don’t even know where they could start learning how much better they could be doing things. For something so essential to so many people’s daily work, data visualization is so rarely directly taught, and is usually assumed to be something people will pick up with time.\nHowever, that isn’t the best approach. Data visualization is a skill like any other, and even experienced practitioners could benefit from honing their skills in the subject. Hence, this short lesson on the topic. This set of three documents contain about the same amount of information as could be covered in a 60-90 minute lecture on the subject.\nAt no point do I intend to teach you how to make a specific graphic in a specific software. I don’t know what softwares might be applicable to your needs in the future, or what visualizations you’ll need to formulate when, and quite frankly Google exists – so this isn’t a cookbook with step-by-step instructions. The goal here is not to provide you with recipes for the future, but rather to teach you what flour is – to introduce you to the basic concepts and building blocks of effective data visualizations.\nThe mantras As much as possible, I’ve collapsed those concepts into four mantras we’ll return to throughout this course. The mantras are:\nA good graphic tells a story. Everything should be made as simple as possible, but no simpler. Use the right tool for the job. Ink is cheap. Electrons are even cheaper.  Each mantra serves as the theme for a section, and will also be interwoven throughout. The theme of this section is, easily enough:\n A good graphic tells a story When making a graphic, it is important to understand what the graphic is for. After all, you usually won’t make a chart that is a perfect depiction of your data – modern data sets tend to be too big (in terms of number of observations) and wide (in terms of number of variables) to depict every datapoint on a single graph. Instead, the analyst consciously chooses what elements to include in a visualization in order to identify patterns and trends in the data in the most effective manner possible. In order to make those decisions, it helps a little to think both about why and how graphics are made.\nWhy do we tell a story? As far as the why question goes, the answer usually comes down to one of two larger categories:\n To help identify patterns in a data set, or To explain those patterns to a wider audience  These are the rationales behind creating what are known as, respectively, exploratory and explanatory graphics. Exploratory graphics are often very simple pictures of your data, built to identify patterns in your data that you might not know exist yet. Take for example a simple graphic, showing tree circumference as a function of age:\nThis visualization isn’t anything too complex – two variables, thirty-five observations, not much text – but it already shows us a trend that exists in the data. We could use this information, if we were so inspired, to start investigating the whys of why tree growth changes with age, now that we’re broadly aware of how it changes.\nExplanatory graphs, meanwhile, are all about the whys. Where an exploratory graphic focuses on identifying patterns in the first place, an explanatory graphic aims to explain why they happen and – in the best examples – what exactly the reader is to do about them. Explanatory graphics can exist on their own or in the context of a larger report, but their goals are the same: to provide evidence about why a pattern exists and provide a call to action. For instance, we can reimagine the same tree graph with a few edits in order to explain what patterns we’re seeing:\nI want to specifically call out the title here: “Orange tree growth tapers by year 4.” A good graphic tells a story, remember. As such, whatever title you give your graph should reflect the point of that story – titles such as “Tree diameter (cm) versus age (days)” and so on add nothing that the user can’t get from the graphic itself. Instead, use your title to advance your message whenever it makes sense – otherwise, if it doesn’t add any new information, you’re better off erasing it altogether.\nThe important takeaway here is not that explanatory graphics are necessarily more polished than exploratory ones, or that exploratory graphics are only for the analyst – periodic reporting, for instance, will often use highly polished exploratory graphics to identify existing trends, hoping to spur more intensive analysis that will identify the whys. Instead, the message is that knowing the end purpose of your graph – whether it should help identify patterns in the first place or explain how they got there – can help you decide what elements need to be included to tell the story your graphic is designed to address.\n How do we tell a story? The other important consideration when thinking about graph design is the actual how you’ll tell your story, including what design elements you’ll use and what data you’ll display. My preferred paradigm when deciding between the possible “hows” is to weigh the expressiveness and effectiveness of the resulting graphic – as defined by Jeffrey Heer at the University of Washington, that means:\n Expressiveness: A set of facts is expressible in a visual language if the sentences (i.e. the visualizations) in the language express all the facts in the set of data, and only the facts in the data.\n Effectiveness: A visualization is more effective than another visualization if the information conveyed by one visualization is more readily perceived than the information in the other visualization.  Or, to simplify:\nTell the truth and nothing but the truth (don’t lie, and don’t lie by omission) Use encodings that people decode better (where better = faster and/or more accurate)  Keep this concept in the back of your mind as we move into our mechanics section – it should be your main consideration while deciding which elements you use! We’ll keep returning to these ideas of explanatory and exploratory, as well as expressiveness and effectiveness, throughout the rest of the sections.\n  ","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570938438,"objectID":"6c81ffc8fcd40fda442d504afae955ab","permalink":"https://www.mikemahoney218.com/tutorials/dataviz/dataviz-theory/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/tutorials/dataviz/dataviz-theory/","section":"tutorials","summary":"Part 1 in the data visualization series","tags":["Data Visualization","Tutorials"],"title":"Theory of Data Visualizations","type":"docs"},{"authors":null,"categories":["Tutorials","DataViz"],"content":" \nLet’s move from theoretical considerations of graphing to the actual building blocks you have at your disposal. As we do so, we’re also going to move on to mantra #2:\nEverything should be made as simple as possible – but no simpler. Graphs are inherently a 2D image of our data:\nThey have an x and a y scale, and - as in our scatter plot here - the position a point falls along each scale tells you how large its values are. But this setup only allows us to look at two variables in our data - and we’re frequently interested in seeing relationships between more than two variables.\nSo the question becomes: how can we visualize those extra variables? We can try adding another position scale:\nBut 3D images are hard to wrap your head around, complicated to produce, and not as effective in delivering your message. They do have their uses - particularly when you’re able to build real, physical 3D models, and not just make 3D shapes on 2D planes - but frequently aren’t worth the trouble.\nSo what tools do we have in our toolbox? The ones that are generally agreed upon (no, really - this is an area of active debate) fall into four categories:\n Position (like we already have with X and Y) Color Shape Size  These are the tools we can use to encode more information into our graphics. We’re going to call these aesthetics, but any number of other words could work - some people refer to them as scales, some as values. I call them aesthetics because that’s what my software of choice calls them - but the word itself comes from the fact that these are the things that change how your graph looks.\nFor what it’s worth, we’re using an EPA data set for this unit, representing fuel economy data from 1999 and 2008 for 38 popular models of car. “Hwy” is highway mileage, “displ” is engine displacement (so volume), and “cty” is city mileage. But frankly, our data set doesn’t matter right now - most of our discussion here is applicable to any data set you’ll pick up.\nWe’re going to go through each of these aesthetics, to talk about how you can encode more information in each of your graphics. Along the way, remember our mantras:\nA good graphic tells a story Everything should be made as simple as possible - but no simpler Use the right tool for the job Ink is cheap. Electrons are even cheaper  We’ll talk about how these are applicable throughout this section.\nPosition Let’s start off discussing these aesthetics by finishing up talking about position. The distance of values along the x, y, or – in the case of our 3D graphic – z axes represents how large a particular variable is. People inherently understand that values further out on each axis are more extreme - for instance, imagine you came across the following graphic (made with simulated data):\nWhich values do you think are higher?\nMost people innately assume that the bottom-left hand corner represents a 0 on both axes, and that the further you get from that corner the higher the values are. This – relatively obvious – revelation hints at a much more important concept in data visualizations: perceptual topology should match data topology. Put another way, that means that values which feel larger in a graph should represent values that are larger in your data. As such, when working with position, higher values should be the ones further away from that lower left-hand corner – you should let your viewer’s subconscious assumptions do the heavy lifting for you.\nApplying this advice to categorical data can get a little tricky. Imagine that we’re looking at the average highway mileages for manufacturers of the cars in our data set:\nIn this case, the position along the x axis just represents a different car maker, in alphabetical order. But remember, position in a graph is an aesthetic that we can use to encode more information in our graphics. And we aren’t doing that here – for instance, we could show the same information without using x position at all:\nTry to compare Pontiac and Hyundai on the first graph, versus on this second one. If anything, removing our extraneous x aesthetic has made it easier to compare manufacturers. This is a big driver behind our second mantra – that everything should be made as simple as possible, but no simpler. Having extra aesthetics confuses a graph, making it harder to understand the story it’s trying to tell.\nHowever, when making a graphic, we should always be aiming to make important comparisons easy. As such, we should take advantage of our x aesthetic by arranging our manufacturers not alphabetically, but rather by their average highway mileage: By reordering our graphic, we’re now able to better compare more similar manufacturers. It’s now dramatically faster to understand our visualization – closer comparisons are easier to make, so placing more similar values closer together makes them dramatically easier to grasp. Look at Pontiac vs Hyundai now, for instance. Generally speaking, don’t put things in alphabetical order - use the order you place things to encode additional information.\nAs a quick sidenote, I personally believe that, when working with categorical values along the X axis, you should reorder your values so the highest value comes first. For some reason, I just find having the tallest bar/highest point (or whatever is being used to show value) next to the Y axis line is much cleaner looking than the alternative:\nFor what it’s worth, I’m somewhat less dogmatic about this when the values are on the Y axis. I personally believe the highest value should always be at the top, as humans expect higher values to be further from that bottom left corner: However, I’m not as instantly repulsed by the opposite ordering as I am with the X axis, likely because the bottom bar/point being the furthest looks like a more natural shape, and is still along the X axis line: For this, at least, your mileage may vary. Also, it’s worth pointing out how much cleaner the labels on this graph are when they’re on the Y axis - flipping your coordinate system, like we’ve done here, is a good way to display data when you’ve got an unwieldy number of categories.\n Color While we’ve done a good job covering the role position plays in communicating information, we’re still stuck on the same question we started off with: How can we show a third variable on the graph?\nOne of the most popular ways is to use colors to represent your third variable. It might be worth talking through how color can be used with a simulated data set. Take for example the following graph: And now let’s add color for our third variable: Remember: perceptual topology should match data topology. Which values are larger?\nMost people would say the darker ones. But is it always that simple? Let’s change our color scale to compare: Sure, some of these colors are darker than others – but I wouldn’t say any of them tell me a value is particularly high or low.\nThat’s because humans don’t percieve hue – the actual shade of a color – as an ordered value. The color a point is doesn’t communicate that the point has a higher or lower value than any other point on the graph. Instead, hue works as an unordered value, which only tells us which points belong to which groupings. In order to tell how high or low a point’s value is, we instead have to use luminescence – or how bright or dark the individual point is.\nThere’s one other axis you can move colors along in order to encode value – how vibrant a color is, known as chroma:\nJust keep in mind that luminescence and chroma – how light a color is and how vibrant it is – are ordered values, while hue (or shade of color) is unordered This becomes relevant when dealing with categorical data. For instance, moving back to the scatter plot we started with:\nIf we wanted to encode a categorical variable in this – for instance, the class of vehicle – we could use hue to distinguish the different types of cars from one another:\nIn this case, using hue to distinguish our variables clearly makes more sense than using either chroma or luminesence:\nThis is a case of knowing what tool to use for the job - chroma and luminescence will clearly imply certain variables are closer together than is appropriate for categorical data, while hue won’t give your audience any helpful information about an ordered variable. Note, though, that I’d still discourage using the rainbow to distinguish categories in your graphics – the colors of the rainbow aren’t exactly unordered values (for instance, red and orange are much more similar colors than yellow and blue), and you’ll wind up implying connections between your categories that you might not want to suggest. Also, the rainbow is just really ugly:\nSpeaking of using the right tool for the job, one of the worst things people like to do in data visualizations is overuse color. Take for instance the following example:\nIn this graph, the variable “class” is being represented by both position along the x axis, and by color. By duplicating this effort, we’re making our graph harder to understand – encoding the information once is enough, and doing it any more times than that is a distraction. Remember the second mantra: Everything should be made as simple as possible – but no simpler. The best data visualization is one that includes all the elements needed to deliver the message, and no more.\nYou can feel free to use color in your graphics, so long as it adds more information to the plot - for instance, if it’s encoding a third variable:\nBut replicating as we did above is just adding more junk to your chart.\nThere’s one last way you can use color effectively in your plot, and that’s to highlight points with certain characteristics:\nDoing so allows the viewer to quickly pick out the most important sections of our graph, increasing its effectiveness. Note that I used shape instead of color to separate the class of vehicles, by the way – combining point highlighting and using color to distinguish categorical variables can work, but can also get somewhat chaotic:\nThere’s one other reason color is a tricky aesthetic to get right in your graphics: about 5% of the population (10% of men, 1% of women) can’t see colors at all. That means you should be careful when using it in your visualizations – use colorblind-safe color palettes (google “ColorBrewer” or “viridis” for more on these), and pair it with another aesthetic whenever possible.\n Shape The easiest aesthetic to pair color with is the next most frequently used – shape. This one is much more intuitive than color – to demonstrate, let’s go back to our scatter plot:\nWe can now change the shape of each point based on what class of vehicle it represents: Imagine we were doing the same exercise as we did with color earlier – which values are larger?\nI’ve spoiled the answer already by telling you what the shapes represent – none of them are inherently larger than the others. Shape, like hue, is an unordered value.\nThe same basic concepts apply when we change the shape of lines, not just points. For instance, if we plot separate trendlines for front-wheel, rear-wheel, and four-wheel drive cars, we can use linetype to represent each type of vehicle:\nBut even here, no one linetype implies a higher or lower value than the others.\nThere are two caveats to be made to this rule, however. For instance, if we go back to our original scatter plot and change which shapes we’re using:\nThis graph seems to imply more connection between the first three classes of car (which are all different types of diamonds) and the next three classes (which are all types of triangle), while singling out SUVs. In this way, we’re able to use shape to imply connection between our groupings - more similar shapes, which differ only in angle or texture, imply a closer relationship to one another than to other types of shape. This can be a blessing as well as a curse - if you pick, for example, a square and a diamond to represent two unrelated groupings, your audience might accidentally read more into the relationship than you had meant to imply.\nIt’s also worth noting that different shapes can pretty quickly clutter up a graph. As a general rule of thumb, using more than 3-4 shapes on a graph is a bad idea, and more than 6 means you need to do some thinking about what you actually want people to take away.\n Size Our last aesthetic is that of size. Going back to our original scatter plot, we could imagine using size like this:\nSize is an inherently ordered value - large size points imply larger values. Specifically, humans perceive larger areas as corresponding to larger values - the points which are three times larger in the above graph are about three times larger in value, as well.\nThis becomes tricky when size is used incorrectly, either by mistake or to distort the data. Sometimes an analyst maps radius to the variable, rather than area of the point, resulting in graphs as the below:\nIn this example, the points representing a cty value of 10 don’t look anything close to 1/3 as large as the points representing 30. This makes the increase seem much steeper upon looking at this chart – so be careful when working with size as an aesthetic that your software is using the area of points, not radius!\nIt’s also worth noting that unlike color – which can be used to distinguish groupings, as well as represent an ordered value – it’s generally a bad idea to use size for a categorical variable. For instance, if we mapped point size to class of vehicle:\nWe seem to be implying relationships here that don’t actually exist, like a minivan and midsize vehicle being basically the same. As a result, it’s best to only use size for continuous (or numeric) data.\n A Tangent Now that we’ve gone over these four aesthetics, I want to go on a quick tangent. When it comes to how quickly and easily humans perceive each of these aesthetics, research has settled on the following order:\nPosition Size Color (especially chroma and luminescence) Shape  And as we’ve discussed repeatedly, the best data visualization is one that includes exactly as many elements as it takes to deliver a message, and no more. Everything should be made as simple as possible, but no simpler.\nHowever, we live in a world of humans, where the scientifically most effective method is not always the most popular one. And since color is inherently more exciting than size as an aesthetic, the practitioner often finds themselves using colors to denote values where size would have sufficed. And since we know that color should usually be used alongside shape in order to be more inclusive in our visualizations, size often winds up being the last aesthetic used in a chart. This is fine - sometimes we have to optimize for other things than “how quickly can someone understand my chart”, such as “how attractive does my chart look” or “what does my boss want from me”. But it’s worth noting, in case you see contradictory advice in the future - the disagreement comes from if your source is teaching the most scientifically sound theory, or the most applicable practice.\n Summary We started off this section with our second mantra: that everything should be made as simple as possible, but no simpler. The first half of that cautions us against overusing aesthetics and against adding too much to a graphic, lest we erode its efficency in conveying information:\nThe second half cautions us against not using all the aesthetics it takes to tell our story, in case we don’t produce the most expressive graphic possible: Instead, we should use exactly as many aesthetics as it takes to tell our story, carefully choosing each to encode the most information possible into our graphics: As for the specific takeaways from this section, I can think of the following:\n Match perceptual and data topology – if a color or position feels like a higher value, use it to represent data that is a higher value Make important comparisons easy – place them near each other, call attention to them Use aesthetics to encode more information into your graphics  Use exactly as many aesthetics as you need – no more, no less.  Don’t place things in alphabetical order Don’t use the rainbow for a color scheme Use ordered aesthetics (like position, chroma, luminescence, and size) to show ordered values (like numeric data) Use unordered aesthetics (like hue or shape) to show unordered values  Let’s transition away from aesthetics, and towards our third mantra:\n  Use the right tool for the job. Think back to our first chart:\nAs you already know, this is a scatter plot - also known as a point graph. Now say we added a line of best fit to it:\nThis didn’t stop being a scatter plot once we drew a line on it – but the term scatter plot no longer really encompasses everything that’s going on here. It’s also obviously not a line chart, as even though there’s a line on it, it also has points.\nRather than quibble about what type of chart this is, it’s more helpful to describe what tools we’ve used to depict our data. We refer to these as geoms, short for geometries – because when you get really deep into things, these are geometric representations of how your data set is distributed along the x and y axes of your graph. I don’t want to get too far down that road – I just want to explain the vocabulary so that we aren’t talking about what type of chart that is, but rather what geoms it uses. Framing things that way makes it easier to understand how things can be combined and reformatted, rather than assuming each type of chart can only do one thing.\nTwo continuous variables This chart uses two geoms that are really good for graphs that have a continuous y and a continuous x - points and lines. This is what people refer to most of the time when they say a line graph - a single smooth trendline that shows a pattern in the data. However, a line graph can also mean a chart where each point is connected in turn:\nIt’s important to be clear about which type of chart you’re expected to produce! I always refer to the prior as a trendline, for clarity.\nThese types of charts have enormous value for quick exploratory graphics, showing how various combinations of variables interact with one another. For instance, many analysts start familiarizing themselves with new data sets using correlation matrices (also known as scatter plot matrices), which create a grid of scatter plots representing each variable:\nIn this format, understanding interactions between your data is quick and easy, with certain variable interactions obviously jumping out as promising avenues for further exploration.\nTo back up just a little, there’s one major failing of scatter plots that I want to highlight before moving on. If you happen to have more than one point with the same x and y values, a scatter plot will just draw each point over the previous, making it seem like you have less data than you actually do. Adding a little bit of random noise - for instance, using RAND() in Excel - to your values can help show the actual densities of your data, especially when you’re dealing with numbers that haven’t been measured as precisely as they could a have been. One last chart that does well with two continuous variables is the area chart, which resembles a line chart but fills in the area beneath the line: Area plots make sense when 0 is a relevant number to your data set – that is, a 0 value wouldn’t be particularly unexpected. They’re also frequently used when you have multiple groupings and care about their total sum:\n(This new data set is the “diamonds” data set, representing 54,000 diamonds sizes, qualities, cut, and sale prices. We’ll be going back and forth using it and the EPA data set from now on.)\nNow one drawback of stacked area charts is that it can be very hard to estimate how any individual grouping shifts along the x axis, due to the cumulative effects of all the groups underneath them. For instance, there are actually fewer “fair” diamonds at 0.25 carats than at 1.0 – but because “ideal” and “premium” spike so much, your audience might draw the wrong conclusions. In situations where the total matters more than the groupings, this is alright – but otherwise, it’s worth looking at other types of charts as a result.\n One continuous variable If instead you’re looking to see how a single continuous variable is distributed throughout your data set, one of the best tools at your disposal is the histogram. A histogram shows you how many observations in your data set fall into a certain range of a continuous variable, and plot that count as a bar plot:\nOne important flag to raise with histograms is that you need to pay attention to how your data is being binned. If you haven’t picked the right width for your bins, you might risk missing peaks and valleys in your data set, and might misunderstand how your data is distributed – for instance, look what shifts if we graph 500 bins, instead of the 30 we used above: An alternative to the histogram is the frequency plot, which uses a line chart in the place of bars to represent the frequency of a value in your data set: Again, however, you have to pay attention to how wide your data bins are with these charts – you might accidentally smooth over major patterns in your data if you aren’t careful! One large advantage of the frequency chart over the histogram is how it deals with multiple groupings – if your groupings trade dominance at different levels of your variable, the frequency graph will make it much more obvious how they shift than a histogram will.\n(Note that I’ve done something weird to the data in order to show how the distributions change below.)  One categorical variable, one continuous If you want to compare a categorical and continuous variable, you’re usually stuck with some form of bar chart:\nThe bar chart is possibly the least exciting type of graph in existence, mostly because of how prevalent it is – but that’s because it’s really good at what it does. Bar charts are one of the most easily interpreted and effective types of visualizations, no matter how exciting they are.\nHowever, some people are really intent on ruining that. Take, for instance, the stacked bar chart, often used to add a third variable to the mix:\nCompare Fair/G to Premium/G. It’s next to impossible to accurately compare the boxes – they don’t share a top or a bottom line, so you can’t really make a comparison. In these situations, it’s a better idea to use a dodged bar chart instead:\nDodged bar charts are usually a better choice for comparing the actual numbers of different groupings. However, this chart does a good job showing one of the limitations dodged bar charts come up against – once you get past 4 or 5 groupings, making comparisons is tricky. In these cases, you’re probably trying to apply the wrong chart for the job, and should consider either breaking your chart up into smaller ones – remember, ink is cheap, and electrons or cheaper – or replacing your bars with a few lines.\nThe one place where stacked bar charts are appropriate, however, is when you’re comparing the relative proportions of two different groups in each bar. For instance, take the following graph:\nIn this case, making comparisons across groups is trivial, made simple by the fact that the groupings all share a common line - at 100% for group 1, and at 0% for group 2. This point of reference solves the issue we had with more than two groupings – though note we’d still prefer a dodged bar chart if the bars didn’t always sum to the same amount.\nA Quick Tangent This is usually where most people will go on a super long rant about pie charts and how bad they are. They’re wrong, but in an understandable way.\nPeople love to hate on pie charts, because they’re almost universally a bad chart. However, if it’s important for your viewer to be able to quickly figure out what proportion two or more groupings make up of the whole, a pie chart is actually the fastest and most effective way to get the point across. For instance, compare the following pie and bar charts, made with the same data set: It’s a lot easier to tell that, say, A is smaller than C through F in the pie chart than the bar plot, since humans are better at summing angles than areas. In these instances, feel free to use a pie chart – and to tell anyone giving you flack that I said it was OK.\n  Two categorical variables Our last combination is when you’re looking to have a categorical variable on both the x and y axis. These are trickier plots to think about, as we no longer encode value in position based on how far away a point is from the lower left hand corner, but rather have to get creative in effectively using position to encode a value. Remember that a geom is a geometric representation of how your data set is distributed along the x and y axes of your graph. When both of your axes are categorical, you have to get creative to show that distribution.\nOne method is to use density, as we would in a scatter plot, to show how many datapoints you have falling into each combination of categories graphed. You can do this by making a “point cloud” chart, where more dense clouds represent more common combinations: Even without a single number on this chart, its message is clear - we can tell how our diamonds are distributed with a single glance. A similar way to do this is to use a heatmap, where differently colored cells represent a range of values:\nI personally think heatmaps are less effective – partially because by using the color aesthetic to encode this value, you can’t use it for anything else – but they’re often easier to make with the resources at hand.\n  ","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570938438,"objectID":"03ee55d62cb93fbb9a8ae41a24f5a9e3","permalink":"https://www.mikemahoney218.com/tutorials/dataviz/dataviz-mechanics/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/tutorials/dataviz/dataviz-mechanics/","section":"tutorials","summary":"Part 2 in the data visualization series","tags":["Data Visualization","Tutorials"],"title":"Mechanics of Data Visualizations","type":"docs"},{"authors":null,"categories":["Tutorials","DataViz"],"content":" \nAs we move into our final section, it’s time to dwell on our final mantra:\nInk is cheap. Electrons are even cheaper. This is a fancy, dogmatic way to say: Make more than one chart. It’s rare that your first try is going to produce your best looking output. Play around with your data set, try out different visuals, and keep the concepts we’ve talked about in mind. Your graphs will be all the better for it. In this section, we’ll talk about solutions to some of the most common problems people have with making charts:\nDealing with big data sets Think back to the diamonds data set we used in the last section. It contains data on 54,000 individual diamonds, including the carat and sale price for each. If we wanted to compare those two continuous variables, we might think a scatter plot would be a good way to do so:\nUnfortunately, it seems like 54,000 points is a few too many for this plot to do us much good! This is a clear case of what’s called overplotting – we simply have too much data on a single graph.\nThere are three real solutions to this problem. First off, we could decide simply that we want to refactor our chart, and instead show how a metric – such as average sale price – changes at different carats, rather than how our data is distributed:\nThere are all sorts of ways we can do this sort of refactoring – if we wanted, we could get a very similar graph by binning our data and making a bar plot:\nEither way, though, we’re not truly showing the same thing as was in the original graph – we don’t have any indication of the actual distribution of our data set along these axes.\nThe second solution solves this problem much more effectively – make all your points semi-transparent:\nBy doing this, we’re now able to see areas where our data is much more densely distributed, something that was lost in the summary statistics – for instance, it appears that low-carat diamonds are much more tighly grouped than higher carat ones. We can also see some dark stripes at “round-number” values for carat – that indicates to me that our data has some integrity issues, if appraisers are more likely to give a stone a rounded number.\nThe challenge with this approach comes when we want to map a third variable – let’s use cut – in our graphic. We can try to change the aesthetics of our graph as usual:\nBut unfortunately the sheer number of points drowns out most of the variance in color and shape on the graphic. In this case, our best option may be to turn to option number three and facet our plots – that is, to split our one large plot into several small multiples:\nRemember: Ink is cheap. Electrons are even cheaper. Make more than one graph.\nBy splitting out our data into several smaller graphics, we’re much better able to see how the distribution shifts between our categories. In fact, we could use this technique to split our data even further, into a matrix of scatter plots showing how different groups are distributed:\nOne last, extremely helpful use of faceting is to split apart charts with multiple entangled lines: These charts, commonly referred to as “spaghetti charts”, are usually much easier to use when split into small multiples:\nNow, one major drawback of facet charts is that they can make comparisons much harder – if, in our line chart, it’s more important to know that most clarities are similar in price at 2 carats than it is to know how the price for each clarity changes with carat, then the first chart is likely the more effective option. In those cases, however, it’s worth reassessing how many lines you actually need on your graph – if you only care about a few clarities, then only include those lines, and if you only care about a narrow band of prices or carats, window your data so that’s all you show. The goal is to make making comparisons easy, with the understanding that some comparisons are more important than others.\n Dealing with chartjunk Cast your mind back to the graphic I used as an example of an explanatory chart:\nYou might have noticed that this chart is differently styled from all the others in this course – it doesn’t have the grey background or grid lines or anything else.\nThink back to our second mantra: everything should be made as simple as possible, but no simpler. This chart reflects that goal. We’ve lost some of the distracting elements – the colored background and grid lines – and changed the other elements to make the overall graphic more effective. The objective is to have no extraneous element on the graph, so that it might be as expressive and effective as possible. This usually means using minimal colors, minimal text, and no grid lines. (After all, those lines are usually only useful in order to pick out a specific value – and if you’re expecting people to need specific values, you should give them a table!)\nThose extraneous elements are known as chartjunk. You see this a lot with graphs made in Excel – they’ll have dark backgrounds, dark lines, special shading effects or gradients that don’t encode information, or – worst of all – those “3D” bar/line/pie charts, because these things can be added with a single click. However, they tend to make your graphics less effective as they force the user to spend more time separating data from ornamentation. Everything should be made as simple as possible, but no simpler; every element of your graphic should increase expressiveness or effectiveness. In short: don’t try to pretty up your graph with non-useful elements.\nAnother common instance of chartjunk is animation in graphics. While animated graphics are exciting and trendy, they tend to reduce the effectiveness of your graphics because as humans, when something is moving we can’t focus on anything else. Check out these examples from the Harvard Vision Lab – they show just how hard it is to notice changes when animation is added. This isn’t to say you can never use animation – but its uses are best kept to times when your graphic looking cool is more important than it conveying information.\n  Common Mistakes As we wind down this section, I want to touch on a few common mistakes that didn’t have a great home in any other section – mostly because we were too busy talking about good design principles.\nDual y axes Chief amongst these mistakes are plots with two y axes, beloved by charlatans and financial advisors since days unwritten. Plots with two y axes are a great way to force a correlation that doesn’t really exist into existence on your chart, through manipulation of your units and axes. In almost every case, you should just make two graphs – ink is cheap. Electrons are even cheaper.\nFor an extremely entertaining read on this subject, check out this link. I’ve borrowed Kieran’s code for the below viz – look at how we can imply different things, just by changing how we scale our axes!\n Overcomplex visualizations Another common issue in visualizations comes from the analyst getting a little too technical with their graphs. For instance, think back to our original diamonds scatter plot: Looking at this chart, we can see that carat and price have a positive correlation – as one increases, the other does as well. However, it’s not a linear relationship; instead, it appears that price increases faster as carat increases.\nThe more statistically-minded analyst might already be thinking that we could make this relationship linear by log-transforming the axes – and they’d be right! We can see a clear linear relationship when we make the transformation:\nUnfortunately, transforming your visualizations in this way can make your graphic hard to understand – in fact, only about 60% of professional scientists can even understand them. As such, transforming your axes like this tends to reduce the effectiveness of your graphic – this type of visualization should be reserved for exploratory graphics and modeling, instead.\n  Conclusion And that just about wraps up this introduction to the basic concepts of data visualizations. Hopefully you’ve picked up some concepts or vocabulary that can help you think about your own visualizations in your daily life. I wanted to close out here with a list of resources I’ve found helpful in making graphics – I’ll keep adding to this over time:\n When picking colors, I often find myself reaching for one of the following tools:  ColorBrewer provided most of the palettes for these graphics ColorSupply makes picking custom colors easier Viridis provides beautiful, colorblind-friendly palettes for use (though this resource is a little harder to understand)  I used the following resources in putting this post together:  Hadley Wickham’s Stat 405 Course, particularly the lecture on effective visualizations (I’ve lifted “perceptual topology should match data toplogy”, “make important comparisons easy”, and “visualization is only one part of data analysis” directly from his slides) Jeffrey Heer’s CSE 442 lecture on visualizations, particularly the definitions for expressiveness and effectiveness    ","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570938438,"objectID":"404852ad8c6af52a8e9f6caec91350ed","permalink":"https://www.mikemahoney218.com/tutorials/dataviz/excellent/","publishdate":"2019-10-09T00:00:00Z","relpermalink":"/tutorials/dataviz/excellent/","section":"tutorials","summary":"Part 3 in the data visualization series","tags":["Data Visualization","Tutorials"],"title":"Making Excellent Visualizations","type":"docs"},{"authors":["Mike Mahoney"],"categories":["Tutorials","Data Visualization"],"content":" I finally got to uploading my Towards Data Science article as a tutorial (using the cool “courses” function of the Hugo academic theme). I personally like this format better than the Medium article – you can check it out at this link.\n","date":1573862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573923772,"objectID":"2a787735787431bec5fbf5fd0868b435","permalink":"https://www.mikemahoney218.com/post/tdstutorial/tutorial-dataviz/","publishdate":"2019-11-16T00:00:00Z","relpermalink":"/post/tdstutorial/tutorial-dataviz/","section":"post","summary":"Same story, new place.","tags":["Publications","Data Visualization","Tutorials"],"title":"The Art and Science of Data Visualization is now live on the site!","type":"post"},{"authors":["Mike Mahoney"],"categories":["Publications","Data Visualization"],"content":" I’m in Towards Data Science today, talking about the theory behind what makes a good visualization and how you can use those concepts to improve your own graphics. The guide is written for all experience levels and doesn’t contain a snippet of code, though – as usual – you can find the R Markdown documents used to build the article on [GitHub].\nThe TDS article can be found at this link – I plan on putting the content on this website, too, once I get the chance.\n","date":1570924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571015652,"objectID":"e089e2f6090860e73f60900887633c33","permalink":"https://www.mikemahoney218.com/post/tdsdataviz/tds-dataviz/","publishdate":"2019-10-13T00:00:00Z","relpermalink":"/post/tdsdataviz/tds-dataviz/","section":"post","summary":"A comprehensive guide on how to think about and create brilliant data visualizations.","tags":["Publications","Data Visualization","Towards Data Science"],"title":"The Art and Science of Data Visualization published in Towards Data Science","type":"post"},{"authors":null,"categories":null,"content":"R Markdown is one of the coolest parts of the R ecosystem, making it trivial to create professional-looking HTML and PDF documents using simple markdown language. heddlr looks to extend that functionality by making it easier to dynamically piece together documents by intelligently using your data to combine defined components into a cohesive whole, leading to cleaner code and faster creation of reports that have many repeating pieces or dashboards which need to respond to changes in their data sources.\nYou can find more information about this project in the documentation, or check out the code on GitHub.\n","date":1558152000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578068795,"objectID":"7ad5a2c1dc208c9641687abb83cbe935","permalink":"https://www.mikemahoney218.com/project/heddlr/","publishdate":"2019-05-18T00:00:00-04:00","relpermalink":"/project/heddlr/","section":"project","summary":"Applying functional programming concepts to Markdown content generation.","tags":["heddlr","R","R-markdown"],"title":"heddlr: Dynamic R Markdown Document Generation","type":"project"},{"authors":null,"categories":null,"content":"There are a lot of resources online to learn R. Some of them are extremely well-written and well-structured, but approach things from a different perspective than I find useful. Some of them are expansive and touch on a massive number of topics, but either don’t go as thoroughly into these topics as might be helpful, or have an interesting writing style or are otherwise hard to follow.\nI’ve got a very specific idea of how R should be taught, at least to those interested in using it for data science and other analytical applications. And so in 2018 I began working on a reader - conceived at the time as a series of lecture notes, to support a 3-credit undergrad course - that could be used to learn R that way. However, as I started giving out copies of the reader to friends for feedback, I noticed that a lot of them found the book useful to learn R on their own, and would rather learn that way than in a lecture environment. As such, I started shifting the content into more of a standalone book, attempting to teach R for use in analysis work in both scientific and business contexts.\nThe book is currently going through a second round of edits, and may be found in its current state at this link. If you find the book helpful (or if you\u0026rsquo;ve got suggestions on how it could be improved), please drop me a line - I love hearing from people who have stumbled across it!\n","date":1558152000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"4976acb22f10f68a5072a8ca5e882e12","permalink":"https://www.mikemahoney218.com/project/idear/","publishdate":"2019-05-18T00:00:00-04:00","relpermalink":"/project/idear/","section":"project","summary":"A how-to primer on using R for data analysis in both scientific and business contexts.","tags":["machine-learning","R","data-analytics","data-science"],"title":"Introduction to Data Exploration and Analysis with R","type":"project"},{"authors":["Mike Mahoney"],"categories":["Publications","Beaver"],"content":"  p.caption { font-size: 0.6em; }  My thesis is now available on the ESF Digital Commons! I’m extremely grateful to Drs. John Drake and Bill Shields for their help in the revision and submission process, and of course to Dr. John Stella for the extensive support he provided throughout the project, from conceptualization to publication.\nIn the thesis, we look at the impacts beavers have on the forest community around them as they remove trees for food and building dams. While people had looked at these impacts in other parts of beaver’s range, the Adirondacks are a strange enough ecosystem - being largely protected from anthropogenic disturbances, most of the forest landscape exhibits only one or two age classes - that we weren’t sure how applicable conclusions from these regions would be. What we found was that while the broad conclusions of these studies held true - beavers still operate as central place foragers and create large disturbances in the landscape - the lack of early-successional species throughout the Adirondacks seriously shifted which stems were harvested preferrentially. We also found a lot of variance in the patterns of how individual species were utilized - for instance, beaver harvested almost any size speckled alder they could find, so long as it was close to their dam, but would harvest red maple at any distance, so long as the stem was small.\nOne figure from the article version of the thesis, showing the odds a stem will be harvested (z-axis) as a function of how far (x-axis, left) and how big (y-axis, right) it is.  \nWe’re currently working on a journal article version of the thesis, using an expanded dataset and focusing more closely on the patterns in forage selectivity we found, and how they differ from other regions. That should hopefully be in the review process within the next few weeks.\n","date":1553644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571099615,"objectID":"004669d262384a65b7f36695c05e16ec","permalink":"https://www.mikemahoney218.com/post/thesispublished/ml-beaver-data/","publishdate":"2019-03-27T00:00:00Z","relpermalink":"/post/thesispublished/ml-beaver-data/","section":"post","summary":"It's a real humdinger.","tags":["Thesis","Publications","Beaver"],"title":"Thesis Now Available in ESF Digital Commons","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://www.mikemahoney218.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Michael J Mahoney"],"categories":null,"content":"","date":1543640400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"9986929e464896e5a175b6f66aac9111","permalink":"https://www.mikemahoney218.com/publication/beaver-thesis/","publishdate":"2018-12-01T00:00:00-05:00","relpermalink":"/publication/beaver-thesis/","section":"publication","summary":"Beavers (Castor canadensis) are ecosystem engineers, causing changes at the landscape level due to a combination of their damming and foraging behaviors. As beaver dam streams, create ponds, and maintain canopy openings, the comprehensive impacts of beaver constitute a rare source of ongoing disturbance in the forests of northeastern North America. Though the behaviors and impacts of beaver on riparian communities have been well studied in several forest regions, they are poorly understood within forests of the northeastern United States, where beaver populations are still rebounding following regional extirpation. Given the unique composition, management history, and disturbance regimes of forests within this region, there is a need for new research to quantify impacts in this region and to compare beaver foraging preferences and disturbance impacts to other regions. I conducted field surveys at 19 beaver sites throughout New York’s Adirondack State Park to assess beaver foraging preferences and the impacts of beaver activity on forest structure and composition. Beavers preferentially harvested stems between 2 and 10 centimeters, with the 2 to 5 centimeter size class most preferred overall. Deciduous tree species were preferentially harvested, with typically disfavored species such as American beech (Fagus grandifolia) harvested at higher rates than in studies from other regions. Logistic regression models showed clear foraging preferences for stems closer to the impoundment of intermediate sizes for all modeled groupings and species. Impacts on forest structure generally resembled those found in other regions, while preferred species differed greatly. Understanding the impacts beavers will have on forests in the Northeast is crucially important as beaver continue to recolonize their historic range, creating new management challenges and opportunities in years to come.","tags":["Beaver","Beaver-Impacts"],"title":"Beaver Foraging Preferences and Impacts on Forest Structure in New York's Adirondack Mountains","type":"publication"},{"authors":null,"categories":["Announcements"],"content":" I was happy to attend the Rochester Academy of Sciences Fall Paper Session this past weekend! It seemed like an incredibly diverse array of work was on display - one particularly notable poster connected human heights and weights to the weight of their cremation remains - and the atmosphere was incredibly welcoming.\nMy talk on beaver impacts seemed to get decent reviews! I’ve posted my slides on SlideShare, and will be posting a rough script of the talk soon enough. I’ve got plans for a few changes before the FEMC conference, coming up in a month.\n","date":1542067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571099615,"objectID":"b53d67e7e686087eb8386420cb82749c","permalink":"https://www.mikemahoney218.com/post/ras2018/one-conference-down/","publishdate":"2018-11-13T00:00:00Z","relpermalink":"/post/ras2018/one-conference-down/","section":"post","summary":"I was happy to attend the Rochester Academy of Sciences Fall Paper Session this past weekend! It seemed like an incredibly diverse array of work was on display - one particularly notable poster connected human heights and weights to the weight of their cremation remains - and the atmosphere was incredibly welcoming.\nMy talk on beaver impacts seemed to get decent reviews! I’ve posted my slides on SlideShare, and will be posting a rough script of the talk soon enough.","tags":[],"title":"One Conference Down, One to Go!","type":"post"},{"authors":["Michael J. Mahoney","John C. Stella"],"categories":null,"content":"","date":1540267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"ce201be86df0302a6a777a1730a79fbf","permalink":"https://www.mikemahoney218.com/talk/femc_2018/","publishdate":"2018-10-23T00:00:00-04:00","relpermalink":"/talk/femc_2018/","section":"talk","summary":"Beavers (*Castor canadensis*) are ecosystem engineers, causing changes at the landscape scale due to a combination of their damming and foraging behaviors. While these behaviors – and the impacts they have on riparian communities – have been well studied in several forest regions, they are poorly understood within the forests of northeastern North America. Field surveys at 19 beaver locations throughout New York’s Adirondack State Park assessed beaver foraging preferences and the impacts of beaver activity on forest structure and composition. Forest canopy closure decreased with proximity to beaver impoundments, and forest structure and composition also varied along this gradient. Beavers preferentially harvested stems between 2 and 10 cm diameter, with the 2 to 5 cm size class most generally preferred. Deciduous species were also preferentially harvested, with typically disfavored species such as American beech (Fagus grandifolia) harvested at higher rates than in studies from other regions. Logistic regression models showed clear foraging preferences for stems closer to the impoundment of intermediate sizes for all modeled groupings and species. Understanding the impacts beavers will have on riparian forests in the Northeast is critical as beaver continue to recolonize their historic range, creating new management challenges and opportunities in years to come.","tags":["Beaver"],"title":"Beaver Foraging Preferences and Impacts on Forest Structure and Composition","type":"talk"},{"authors":["Michael J. Mahoney","John C. Stella"],"categories":null,"content":"","date":1540267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"aba7a0377602374c7f2f7a65ffa3ba6e","permalink":"https://www.mikemahoney218.com/talk/ras_2018/","publishdate":"2018-10-23T00:00:00-04:00","relpermalink":"/talk/ras_2018/","section":"talk","summary":"Beavers (*Castor canadensis*) are ecosystem engineers, causing changes at the landscape scale due to a combination of their damming and foraging behaviors. While these behaviors – and the impacts they have on riparian communities – have been well studied in several forest regions, they are poorly understood within the forests of northeastern North America. Field surveys at 19 beaver locations throughout New York’s Adirondack State Park assessed beaver foraging preferences and the impacts of beaver activity on forest structure and composition. Forest canopy closure decreased with proximity to beaver impoundments, and forest structure and composition also varied along this gradient. Beavers preferentially harvested stems between 2 and 10 cm diameter, with the 2 to 5 cm size class most generally preferred. Deciduous species were also preferentially harvested, with typically disfavored species such as American beech (Fagus grandifolia) harvested at higher rates than in studies from other regions. Logistic regression models showed clear foraging preferences for stems closer to the impoundment of intermediate sizes for all modeled groupings and species. Understanding the impacts beavers will have on riparian forests in the Northeast is critical as beaver continue to recolonize their historic range, creating new management challenges and opportunities in years to come.","tags":["Beaver"],"title":"Beaver Foraging Preferences and Impacts on Forest Structure and Composition","type":"talk"},{"authors":null,"categories":null,"content":"The widespread reforestation of the Northeastern United States has been accompanied by a reintroduction of beaver (Castor canadensis) throughout the region, resulting in profound changes to stream and meadow ecosystems. In contrast to the large body of research on beaver biology and their wetlands, impacts to the adjacent forest from these \u0026lsquo;ecosystem engineers\u0026rsquo; are poorly understood. We are studying the dynamic relationship between landscape drivers of long-term site use by beavers and their reciprocal influence on forest communities adjacent to their ponds. At a SUNY-ESF research forest in the Adirondack Mountains of New York State, we are using a 30-year record of beaver lodge occupancy to (1) test a process-based model of landscape controls on the duration of beaver occupancy; and (2) quantify the spatially-varying impacts of beaver foraging on forest tree composition and structure. This research will help to better understand the widespread and long-term effects on forests from a keystone species that is increasing in influence throughout North American and Europe.\nMy current focus is on expanding work done on beaver impacts within the Huntington Wildlife Forest (HWF) to public lands throughout the Adirondacks, to see if the results from our small-scale study at the HWF are applicable to the greater Park. This research may have truly exciting implications for land management moving forward - adaptive management of beaver recolonization has promising applications in wetlands restoration, endangered species recovery, and ecosystem remediation, just to name a few areas.\nIf you\u0026rsquo;re interested in seeing an interactive map of my field sites, click here!\nCollaborators:\n Stacy McNulty (SUNY-ESF) Jacqueline Frair (SUNY-ESF) Joe Wheaton (Utah State University)  Selected Presentations:\nLinks lead to posters or slides for that presentation.\nMahoney, M. J., and Stella, J. C. (2018). Beaver Foraging Preferences and Impacts on Forest Structure in the Adirondack Mountains of New York. Contributed talk at the Forest Ecosystem Monitoring Collective Conference, Burlington, VT.\nMahoney, M. J., and Stella, J. C. (2018). Beaver Foraging Preferences and Impacts on Forest Structure in the Adirondack Mountains of New York. Contributed talk at the Rochester Academy of Sciences Fall Scientific Paper Session, Geneseo, NY.\nMahoney, M. J., Zevin, R., and Stella, J.C. (2018). Impacts of Beaver on Forest Structure and Composition. Poster session presented at the Spotlight on Student Research, Syracuse, NY. [Poster]\n","date":1540267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"68703e6827950df3c7e99ba57516c850","permalink":"https://www.mikemahoney218.com/project/beaverimpacts/","publishdate":"2018-10-23T00:00:00-04:00","relpermalink":"/project/beaverimpacts/","section":"project","summary":"Investigating beaver foraging preferences and landscape-level impacts in New York's Adirondack State Park.","tags":["Beaver"],"title":"Impacts of Beaver on Forest Structure and Composition","type":"project"},{"authors":null,"categories":null,"content":"Although beech bark disease was first detected in North America almost 130 years ago, questions remain about this stand-restructuring pathosystem. Two phloem-feeding beech scale insects, Cryptococcus fagisuga, an invasive species and Xylococcus betulae, a native species, predispose American beech (Fagus grandifolia) to infection by Neonectria ditissima and N. faginata, fungal pathogens believed to be a cause of beech decline. While it is known that high bark N:P predisposes trees to BBD, it is unknown whether N or P affects which of the causal organisms are involved.\nAs part of the Multiple Element Limitation in Northern Hardwood Ecosystem project (MELNHE), experimental plots have been established within Bartlett Experimental Forest in Bartlett, New Hampshire in order to investigate the impact of nutrient additions on this pathosystem. These plots – located within nine stands of three distinct age classes – have been maintained as controls or fertilized each year since 2011 with either nitrogen, phosphorous, or a combination of both nitrogen and phosphorous. Fungal samples and photographs were collected from these experimental plots in summer and fall of 2017. By quantifying the densities of scale insect and the relative proportions of Neonectria species across plots of different treatments, we hope to understand how nutrient additions impact the causal organisms of beech bark disease.\nSelected Presentations:\nLinks lead to posters or slides for that presentation.\nDillon, G., Mahoney, M. J., Chase, S., and Johnston, M. (2019). Nutritional Impacts on Invasive Beech Scale Quantification in Beech Bark Disease Aftermath Forests. Poster session presented at the New York Society of American Foresters Annual Meeting, Syracuse, NY.\nMahoney, M. J., Leimanis, V., Desrochers, M. L., Giambona, B., Johnston, M. T., Yanai, R. D., and Dillon, G. A. (2018) Impacts of Fertilization on Causal Organisms of Beech Bark Disease. Poster session presented at the Spotlight on Student Research, Syracuse, NY. [Poster]\nLasser, G. A., Johnston, M., Mahoney, M., Leimanis, V., and Stoodley, J. (2017). An Investigation of Nutritional Effects on Beech Bark Disease Causal Organisms. Poster session presented at the Forest Ecosystem Monitoring Collective Conference, Burlington, VT.\nLasser, G. A., Johnston, M., Mahoney, M., Leimanis, V., and Stoodley, J. (2017). An Investigation of Nutritional Effects on Beech Bark Disease Causal Organisms. Poster session presented at the Rochester Academy of Sciences Fall Scientific Paper Session, Rochester, NY.\n","date":1540267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570679368,"objectID":"5746e17953d853153565c53234a50654","permalink":"https://www.mikemahoney218.com/project/beechbark/","publishdate":"2018-10-23T00:00:00-04:00","relpermalink":"/project/beechbark/","section":"project","summary":"Investigating the disease ecology of beech bark disease in the White Mountains of New Hampshire.","tags":["Beech-Bark"],"title":"Impacts of Fertilization on Beech Bark Disease","type":"project"},{"authors":["Mike Mahoney"],"categories":null,"content":" title: “The Art and Science of Data Visualization published in Towards Data Science” authors: [admin] date: ‘2019-10-13’ slug: tds-dataviz categories: - Publications - Data Visualization tags: [“Publications”, “Data Visualization”, “Towards Data Science”] image: caption: ’’ focal_point: ’’ summary: “A comprehensive guide on how to think about and create brilliant data visualizations.” —\nI’m thrilled to be speaking at two conferences this fall, both on my work with beaver in the Adirondacks.\nThe conferences are:\nThe Rochester Academy of Sciences Fall Paper Session\nGeneseo, New York\nNovember 9, 9:30 AM\nBailey Hall Room 201\nThe Forest Ecosystem Monitoring Collaborative Conference\nBurlington, Vermont\nDecember 14, 11:30 AM\nDavis Center RTBA\nI’ll be posting my slides and talk notes here following each conference.\n","date":1540252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571099615,"objectID":"a5668c0c17011b338091695af5a9c65d","permalink":"https://www.mikemahoney218.com/post/twofallconf2018/2018-10-23-two-fall-conferences/","publishdate":"2018-10-23T00:00:00Z","relpermalink":"/post/twofallconf2018/2018-10-23-two-fall-conferences/","section":"post","summary":"I'll be presenting at two new conferences this fall.","tags":["Announcements","Conferences"],"title":"Two Fall Conferences","type":"post"},{"authors":null,"categories":["Other"],"content":" Welcome to my new site! I’ll be using this site to post links to talks I give, packages I work on, and future publications. Please excuse me as I get this site off the ground - things are a little barren at the moment, but should get better as we go!\n","date":1540252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571099615,"objectID":"1183cab1f8a1ceb367dde9df6e0b9c7c","permalink":"https://www.mikemahoney218.com/post/newsite/welcome-to-the-new-site/","publishdate":"2018-10-23T00:00:00Z","relpermalink":"/post/newsite/welcome-to-the-new-site/","section":"post","summary":"Welcome to my new site! I’ll be using this site to post links to talks I give, packages I work on, and future publications. Please excuse me as I get this site off the ground - things are a little barren at the moment, but should get better as we go!","tags":[],"title":"Welcome to the New Site!","type":"post"}]